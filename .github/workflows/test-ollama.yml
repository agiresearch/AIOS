# .github/workflows/test-ollama.yml
name: Test Ollama

on:
  pull_request:
    branches: [ "main" ]
  push:
    branches: [ "main" ]

permissions:
  contents: read
  actions: write

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest

    env:
      OLLAMA_MAX_WAIT: 60
      KERNEL_MAX_WAIT: 60

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Clone Cerebrum
        uses: sudosubin/git-clone-action@v1.0.1
        with:
          repository: agiresearch/Cerebrum
          path: Cerebrum

      - name: Install Cerebrum (editable)
        run: python -m pip install -e Cerebrum/

      - name: Install Ollama
        run: curl -fsSL https://ollama.com/install.sh | sh

      - name: Pull Ollama model
        run: ollama pull qwen2.5:7b

      - name: Start Ollama
        run: |
          ollama serve > ollama-llm.log 2>&1 &
          for ((i=1;i<=${OLLAMA_MAX_WAIT};i++)); do
            curl -s http://localhost:11434/api/version && echo "Ollama ready" && break
            echo "Waiting for Ollama… ($i/${OLLAMA_MAX_WAIT})"; sleep 1
          done
          curl -s http://localhost:11434/api/version > /dev/null \
            || { echo "❌  Ollama failed to start"; exit 1; }

      - name: Start AIOS kernel
        run: |
          bash runtime/launch_kernel.sh > kernel.log 2>&1 &
          
      - name: Run tests
        run: |
          mkdir -p test_results
          mapfile -t TESTS < <(find . -type f -path "*/llm/ollama/*" -name "*.py")
          if [ "${#TESTS[@]}" -eq 0 ]; then
            echo "⚠️  No llm/ollama tests found – skipping."
            exit 0
          fi
          for t in "${TESTS[@]}"; do
            echo "▶️  Running $t"
            python "$t" | tee -a test_results/ollama_tests.log
            echo "----------------------------------------"
          done

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs
          path: |
            ollama-llm.log
            kernel.log
            test_results/
