name: Test Ollama

on:
  pull_request:                       # test the code that lives in the PR
    branches: [ "main" ]

  push:                               # test direct pushes to main
    branches: [ "main" ]              # …but see “early-skip” step below

permissions:
  contents: read
  actions: write                      # needed for concurrency-cancellation

# Guarantee only ONE run per PR (new pushes cancel the old run)
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Clone Cerebrum
        uses: sudosubin/git-clone-action@v1.0.1
        with:
          repository: agiresearch/Cerebrum
          path: Cerebrum

      - name: Install Cerebrum (editable)
        run: python -m pip install -e Cerebrum/

      - name: Install Ollama
        run: curl -fsSL https://ollama.com/install.sh | sh

      - name: Pull Ollama model
        run: ollama pull qwen2.5:7b

      - name: Start Ollama
        run: |
          ollama serve > ollama-llm.log 2>&1 &
          for i in {1..30}; do
            curl -s http://localhost:11434/api/version && break
            echo "Waiting for Ollama...($i/30)"; sleep 1
          done

      - name: Start AIOS kernel
        run: |
          bash runtime/launch_kernel.sh > kernel.log 2>&1 &
          for i in {1..60}; do
            curl -s http://localhost:8000/health && break
            echo "Waiting for kernel...($i/60)"; sleep 1
          done

      - name: Run tests (only those in */llm/* with “ollama” in filename)
        run: |
          mkdir -p test_results
          mapfile -t TESTS < <(find tests -type f -path "*/llm/ollama/*" -name "*.py")
          for t in "${TESTS[@]}"; do
            echo "▶️  Running $t"
            python "$t" | tee -a test_results/ollama_tests.log
            echo "----------------------------------------"
          done

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: logs
          path: |
            ollama-llm.log
            kernel.log
            test_results/
